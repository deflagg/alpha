run:
  name: falcon_ts_bpe8k
  seed: 42
  device: cuda
  out_dir: artifacts/runs

data:
  hf_dataset: roneneldan/TinyStories
  raw_dir: data/raw/tinystories_subsample
  processed_dir: data/processed/ts_bpe8k_seq128
  seq_len: 128
  subsample:
    enabled: true
    method: shuffle_select
    seed: 42
    train_n: 529930
    test_n: 5000
    validation_n: null

tokenizer:
  out_dir: artifacts/tokenizers/bpe8k_ts
  vocab_size: 8192
  special_tokens: ["<pad>", "<bos>", "<eos>", "<unk>"]

model:
  type: falcon
  d_model: 256
  n_layers: 6
  n_heads: 4
  d_ff: 1024
  max_seq_len: 128
  prenorm: true
  dropout: 0.0
  tie_weights: true
  moe:
    n_experts: 8
    top_k: 2
    capacity_factor: 1.25
    drop_tokens: true
    router_aux_coef: 0.01
    router_zloss_coef: 1.0e-3
    d_ff_expert: null

train:
  batch_size: 64
  max_steps: 20000
  eval_every: 100
  save_every: 1000
  grad_clip: 1.0
  amp: true
  early_stop_patience: 0        # int; 0 disables early stopping
  early_stop_min_delta: 0.0     # float; required improvement in val_loss
  early_stop_min_step: 0        # int; don't early-stop before this step

optim:
  lr: 3.0e-4
  betas: [0.9, 0.95]
  weight_decay: 0.0

sched:
  warmup_steps: 200
  min_lr: 3.0e-5

logging:
  wandb: true
  wandb_project: tiny-baseline-lm
  log_every: 50
