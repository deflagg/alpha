run:
  name: baseline_wt2_bpe8k
  seed: 42
  device: cuda
  out_dir: artifacts/runs

data:
  hf_dataset: roneneldan/TinyStories
  raw_dir: data/raw/tinystories_subsample
  processed_dir: data/processed/ts_bpe8k_seq128
  seq_len: 128
  subsample:
    enabled: true
    method: shuffle_select
    seed: 42
    train_n: 529930
    test_n: 5000
    validation_n: null

tokenizer:
  out_dir: artifacts/tokenizers/bpe8k_wt2
  vocab_size: 8192
  special_tokens: ["<pad>", "<bos>", "<eos>", "<unk>"]

model:
  d_model: 256
  n_layers: 6
  n_heads: 4
  d_ff: 1024
  max_seq_len: 128
  prenorm: true
  dropout: 0.0
  tie_weights: true

train:
  batch_size: 64
  max_steps: 20000
  eval_every: 100
  save_every: 1000
  grad_clip: 1.0
  amp: true

optim:
  lr: 3.0e-4
  betas: [0.9, 0.95]
  weight_decay: 0.0

sched:
  warmup_steps: 200
  min_lr: 3.0e-5

logging:
  wandb: true
  wandb_project: tiny-baseline-lm
  log_every: 50
